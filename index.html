<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Welcome to Ting Han's Homepage</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <div class="logo">3DAILab Ting Han</div>
    <nav class="nav-links">
      <a href="index.html">Home</a>
      <a href="research.html">Research</a>
      <!-- <a href="project.html">Project</a> -->
      <!-- <a href="experiences.html">Experiences</a> -->
      <a href="act.html">Activities</a>
      <!-- <a href="index_v1.html">Portfolio v1</a> -->
    </nav>
    <button class="menu-toggle" id="menu-toggle">‚ò∞</button>
  </header>
  
  <!-- MAIN CONTENT -->
  <main>
    <div class="intro-container">
    <section class="intro-section">
        <div class="left-column">
          <img src="images/Ting-Han.jpg" alt="Ting-Han" class="intro-photo" />
          <!-- Icons to click-->
          <div class="icon-links">
            <a href="https://github.com/Ting-Devin-Han" target="_blank" rel="noopener" class="icon-link">
              <img src="images/icons/github.svg" alt="GitHub" />
              <span class="icon-label">GitHub</span>
            </a>
           <!--  <a href="https://www.linkedin.com/in/chenshu-liu-381459175/" target="_blank" rel="noopener">
              <img src="images/icons/linkedin.svg" alt="LinkedIn" />
            </a> -->
            <a href="https://scholar.google.com/citations?user=IVWx-jwAAAAJ" target="_blank" rel="noopener" class="icon-link">
                <img src="images/icons/googlescholar.svg" alt="Google Scholar" />
                <span class="icon-label">Scholar</span>
              </a>
            <a href="mailto:hant23@mail2.sysu.edu.cn" class="icon-link">
              <img src="images/icons/email.svg" alt="Email" />
              <span class="icon-label">SYSU Email</span>
            </a>
            <a href="mailto:ting.devin.han@gmail.com" class="icon-link">
              <img src="images/icons/email.svg" alt="Email" />
              <span class="icon-label">Gmail</span>
            </a>
            <!-- <a href="Chenshu_Liu_CV.pdf", target="_blank", rel="noopener">
                <img src="images/icons/cv.svg" alt="CV" />
              </a> -->
          </div>
          <!-- timeline-->
           <div>
            <div class="timeline-header">
                <h2 class="timeline-title">Experience</h2>
                <!-- <p class="timeline-description">‚ÄúLooking back, this journey is filled with moments of growth, challenges overcome, and valuable lessons learned. Each step has shaped who I am today.‚Äù</p> -->
              </div>
            <div class="timeline-vertical-wrapper">
                <div class="timeline-vertical">
                  <div class="timeline-item">
                    <div class="circle"></div>
                    <p class="timeline-label">2025.3<br><span>Joint Ph.D. Student @ SAIT</span></p>
                  </div>
                  <div class="timeline-item">
                    <div class="circle"></div>
                    <p class="timeline-label">2023.9<br><span>Ph.D. Student @ SYSU</span></p>
                  </div>
                  <div class="timeline-item">
                    <div class="circle"></div>
                    <p class="timeline-label">2020.9<br><span>M.Sc. Student @ JMU</span></p>
                  </div>
                  <div class="timeline-item">
                    <div class="circle"></div>
                    <p class="timeline-label">2015.9<br><span>B.Sc. Student @ SXU</span></p>
                  </div>
                  <!-- Add more items as needed -->
                </div>
              </div>

           </div>
 
                  
        </div>
        
        <div class="right-column">
        <div class="intro-text">
          <h1>Hello, I'm Ting Han (Èü©Ê±Ä)</h1>
          <div class="highlight-quote">
            <p>The best way to predict the future is to create it.</p>
          </div>
          
          <p>I am currently a second year Ph.D. student in <a href="https://sges.sysu.edu.cn/">School of Geospatial Engineering and Science</a>, <a href="https://www.sysu.edu.cn/">Sun Yat-Sen University</a>, majoring in <strong>Cartography and Geographic Information System</strong>, under the supervision of Professor <a href="https://3dspatiotemporalailab.github.io/3DAILab-main/"><strong>Yiping Chen</strong></a>.</p>
          <p>I am also a joint Ph.D. student for <strong>Sustainable Urban Development</strong> in <a href="https://www.siat.ac.cn/">Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</a>, under the guidance of Associate Researcher <a href="https://people.ucas.edu.cn/~sunliqun"><strong>Liqun Sun</strong></a>.</p>
          <p>I graduated from the School of Computer Engineering at Jimei University for my master's degree in <strong>Information and Communication Engineering</strong>, where my advisor was Professor <a href="https://cec.jmu.edu.cn/info/1008/4123.htm"><strong>Guorong Cai</strong></a>.</p>
        </div>
        <div class="additional-text">
            <h1>Topics of Interest</h1>
            <p>
              My research interests focus on advancing <strong>geospatial artificial intelligence</strong> by integrating <strong>deep learning theories and methods</strong> into 3D point cloud processing for <strong>remote sensing applications</strong>. 
              I aim to develop <strong>interpretable and generalizable AI models</strong> that can effectively analyze <strong>urban morphology</strong>, <strong>vegetation structure</strong>, and <strong>built environments</strong> from multi-source geospatial data. 
              My work emphasizes the synergy of <strong>spatial cognition</strong> and <strong>data-driven intelligence</strong>, promoting sustainable development through <strong>urban analytics</strong>, <strong>environmental monitoring</strong>, and <strong>human-centered geoinformation services</strong>.
              I am particularly interested in how <strong>multi-modal learning</strong> and <strong>foundation models</strong> can enhance geospatial understanding at <strong>global and city scales</strong>.
              </p>
              
              <!-- <img src="images/Asset 1.png" alt="research_interest" style="margin-bottom: 2rem;" /> -->

            <!-- Featured Publications -->
            <h1>Selected Publications</h1>
            <div class="featured-publications">
              <div class="pub-item">
                <div class="pub-image">
                  <img src="images/research_figures/Scene4U.gif" alt="Scene4U" />
                </div>
                <div class="pub-content">
                  <h3>Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image</h3>
                  <p>Zilong Huang, Jun He, <strong>Ting Han*</strong>, et al.</p>
                  <p><em>CVPR 2025</em> (CCF-A)</p>
                </div>
              </div>
              <div class="pub-item">
                <div class="pub-image">
                  <img src="images/research_figures/HSPFormer.gif" alt="HSPFormer" />
                </div>
                <div class="pub-content">
                  <h3>HSPFormer: Hierarchical Spatial Perception Transformer for Semantic Segmentation</h3>
                  <p>Siyu Chen<sup>#</sup>, <strong>Ting Han<sup>#</strong>, Changshe Zhang, et al.</p>
                  <p><em>IEEE TITS 2025</em> (JCR Q1, IF=8.5, CCF-B)</p>
                </div>
              </div>
            </div>
            <div class="pub-item">
              <div class="pub-image">
                <img src="images/research_figures/ASGFormer.gif" alt="ASGFormer" />
              </div>
              <div class="pub-content">
                <h3>Point Cloud Semantic Segmentation with Adaptive Spatial Structure Graph Transformer</h3>
                <p><strong>Ting Han</strong>, Yiping Chen*, Jin Ma, et al.</p>
                <p><em>JAG 2024</em> (JCR Q1, IF=7.6)</p>
              </div>
            </div>
          <div class="pub-item">
            <div class="pub-image">
              <img src="images/research_figures/Epurate.gif" alt="Epurate" />
            </div>
            <div class="pub-content">
              <h3>Epurate-Net: Efficient Progressive Uncertainty Refinement Analysis for Traffic Environment Urban Road Detection</h3>
              <p><strong>Ting Han</strong>, Siyu Chen, Guorong Cai*, et al.</p>
              <p><em>IEEE TITS 2024</em> (JCR Q1, IF=8.5, CCF-B)</p>
            </div>
          </div>

            <!-- Skills & Expertise -->
            <h1>Expertise</h1>
            <div class="skills-section">
              <div class="skill-category">
                <h3>üî¨ Research Areas</h3>
                <div class="skill-tags">
                  <span class="skill-tag">Computer Vision</span>
                  <span class="skill-tag">3D Point Clouds</span>
                  <span class="skill-tag">Remote Sensing</span>
                  <span class="skill-tag">Urban Analytics</span>
                  <span class="skill-tag">Deep Learning</span>
                </div>
              </div>
            </div>

            <div class="skills-section">
              <div class="skill-category">
                <h3>üìå Awards and Certifications</h3>
                <div style="max-height: 300px; overflow-y: auto; border: 1px solid #e0e4ea; border-radius: 12px; padding: 18px 22px; background: #fff; box-shadow: 0 4px 16px rgba(60,72,88,0.08); transition: box-shadow 0.2s; scrollbar-width: thin; scrollbar-color: #b3b3b3 #f5f5f5;">
                  <ol style="padding-left: 20px; margin: 0;">
                    <li style="margin-bottom: 10px;"><strong>First Prize</strong> in the 3D LiDAR Point Cloud Data Processing Competition at the 8th National LiDAR Conference, 2024. (1#)</li>
                    <li style="margin-bottom: 10px;"><strong>Best Paper Award</strong> at the 2nd Global Forum on Space Information for Sustainable Development, 2024. (1#)</li>
                    <li style="margin-bottom: 10px;"><strong>Best Paper Award</strong> at the 7th National Conference on LiDAR, 2023. (1#)</li>
                    <li style="margin-bottom: 10px;"><strong>Best Paper Award</strong> at the 8th National Conference on LiDAR, 2024. (2#)</li>
                    <li style="margin-bottom: 10px;"><strong>Best Paper Award</strong> at the 1st Global Forum on Space Information for Sustainable Development, 2023. (2#)</li>
                    <li style="margin-bottom: 10px;"><strong>Second Prize of Geographic Information Technology Progress Award</strong>, 2024. (12#)</li>
                    <li style="margin-bottom: 10px;">Honourable Mention at the 1st CVPR Workshop on Urban Scene Modeling: Where Vision Meets Photogrammetry and Graphics - Building3D Competition, 2024. (2#)</li>
                    <li style="margin-bottom: 10px;">Bronze Award at Application Track in Huawei Ascend AI Innovation Competition, Fujian, 2023. (2#)</li>
                    <li style="margin-bottom: 10px;">First-Class Graduate Academic Scholarship at Sun Yat-sen University, 2024.</li>
                    <li style="margin-bottom: 10px;">Outstanding Graduate at Jimei University, 2023.</li>
                    <li style="margin-bottom: 10px;">Second-Class Graduate Academic Scholarship at Jimei University, 2020-2022.</li>
                    <li style="margin-bottom: 10px;">Outstanding Graduate at Shanxi University, 2019.</li>
                  </ol>
                </div>
              </div>
            </div>

            <div class="skills-section">
              <div class="skill-category">
                <h3>‚ú® Miscellaneous Experience</h3>
                <div style="max-height: 300px; overflow-y: auto; border: 1px solid #e0e4ea; border-radius: 12px; padding: 18px 22px; background: #fff; box-shadow: 0 4px 16px rgba(60,72,88,0.08); transition: box-shadow 0.2s; scrollbar-width: thin; scrollbar-color: #b3b3b3 #f5f5f5;">
                  <ol style="padding-left: 20px; margin: 0;">
                    <li style="margin-bottom: 10px;">Teaching Assistant for Computer Vision and Pattern Recognition Course (2023-2025).</li>
                    <li style="margin-bottom: 10px;">Mangrove 3D Point Cloud Data Collection.</li>
                    <li style="margin-bottom: 10px;">Co-author of the Monograph "Spatio-temporal Emergency Response".</li>
                    <li style="margin-bottom: 10px;">Reviewer of IEEE T-CYB, IEEE T-II, IEEE T-ITS, IEEE T-GRS, IEEE T-CSVT, JAG, IEEE IoT, IEEE RAL</li>
                    <li style="margin-bottom: 10px;">Reviewer of CVPR, ACM MM, ICRA, IROS, ICME</li>
                  </ol>
                </div>
              </div>
            </div>

        </div>
    </div>
        
      </section>
    </div>
      
  </main>

  <footer>
    <p>&copy; 3DAI Lab Ting Han. All rights reserved.</p>
  </footer>

  <script src="script.js"></script>
</body>
</html>
